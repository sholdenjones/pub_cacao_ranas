---
title: "process"
author: "Holden Jones"
date: "2025-07-09"
output: html_document
---

script for data processing

#1. Load libraries

```{r}
library(tidyverse)
library(vegan)
library(labdsv)
```

define file path for processed outputs
```{r}
# this will be consistent for each output in this script
data_dir <- file.path(".", "data/processed_data")
```


#2. new

ranas - individual occurrence data across all sites
```{r}
# read raw ranas data
ranas <- read_csv("data/raw_data/ranas_07_14_25.csv") %>%
  dplyr::select(-...20, -...21) # remove dummy columns 

# format dates
ranas$sample_date <- as.Date(ranas$Fecha, format = "%d/%m/%y")

ranas <- ranas %>%
  mutate(year = substr(sample_date, 1, 4))

# need to change VC-V to VC-N, turns out this site was not actually abandoned!
ranas <- ranas %>%
  mutate(Sitio = replace(Sitio, Sitio == "VC-V", "VC-N"))

ranas$Tipo[ranas$Sitio == "VC-N"] <- "N"

# change all epibou to epiesp 
# Lopez-Hervas et al. 2024 show that epibou in this area is actually epiesp
ranas$Final_ID[ranas$Final_ID == "epibou"] <- "epiesp"
```

new - only unique ind. from ranas. Used in analyses
```{r}
new <- ranas %>%
  filter(Recap == "N") # excludes recaptured individuals

# explore / check how many species - 31
new %>%
  group_by(Final_ID) %>%
  count()

# output
# filename <- "new_processed.csv"
# filepath <- file.path(data_dir, filename)
# write_csv(new, file = filepath)
```


#3. site_data

## add environmental data

environmental - environmental data collected for each sampling event
```{r}
# environmental data - change VC-V to VC-N
environmental <- read_csv("data/raw_data/environment_07_12_24.csv")

environmental$sample_date <- as.Date(environmental$Fecha, format = "%d/%m/%y")

environmental <- environmental %>%
  mutate(year = substr(sample_date, 1, 4))

# update VC-N
environmental <- environmental %>%
  mutate(Sitio = replace(Sitio, Sitio == "VC-V", "VC-N"))

environmental$Tipo[environmental$Sitio == "VC-N"] <- "N"
```

'fill in' veg and hoja columns
- these were measured during first site visit in each sampling round
- if no change between subsequent visits, wrote 'same' - vast majority

fill these columns based on values of previous visit
```{r}
environmental <- environmental %>%
  group_by(Sitio, Fecha, Transecto, Bloque) %>%
  mutate(Veg_fill = if_else(Veg == 'same', NA_character_, Veg),
         Hoja_fill = if_else(Hoja =='same', NA_character_, Hoja))

# this needs to also group by year
environmental <- environmental %>%
  group_by(Sitio, year, Transecto, Bloque) %>%
  fill(Veg_fill, .direction = "down") %>%
  fill(Hoja_fill, .direction = "down") %>%
  ungroup()

# now make 'Veg_fill' the only veg column to avoid confusion, same for Hoja
environmental <- environmental %>%
  dplyr::select(-c('Veg', 'Hoja'))
```

now calculate site means for veg, hoja
```{r}
environmental$Veg_fill <- as.numeric(environmental$Veg_fill)
environmental$Hoja_fill <- as.numeric(environmental$Hoja_fill)

environmental <- environmental %>%
  group_by(Sitio) %>%
  mutate(site_mean_hoja = mean(Hoja_fill),
         site_mean_veg = mean(Veg_fill))
```

remove unnecessary columns and rows
- for what we're doing, only need Sitio, site_mean_hoja, site_mean_veg
- just need one row per site
```{r}
environmental_site <- environmental %>% 
  dplyr::select(c('Sitio', 'site_mean_hoja', 'site_mean_veg')) %>%
  group_by(Sitio) %>%
  filter(!duplicated(Sitio))
```


## create site_data

site_data - this df will have all response and predictor vars for each site
- create by merging environmental_site and site_data created from trans_data

trans_data - location, canopy cover, pair, miscellaneous data for each transect
- collected during transect establishment
```{r}
trans_data <- read_csv("data/raw_data/trans_data_08_01_25.csv")

# change VC-V to VC-N
trans_data <- trans_data %>%
  mutate(Sitio = replace(Sitio, Sitio == "VC-V", "VC-N"))

trans_data$Tipo[trans_data$Sitio == "VC-N"] <- "N"

# filter out location info for each transect, notes for finding sites
trans_data <- trans_data %>%
  dplyr::select(-c('Start UTM 1', 'Start UTM 2', 'End UTM 1', 'End UTM 2', 
            'End Latitude', 'End Longitude', 'Notas'))

# calculate transect mean canopy cover and then remove CC cols
trans_data <- trans_data %>%
  rowwise() %>%
  mutate(tran_mean_CC = mean(c_across(`CC A`:`CC D`), na.rm = TRUE))

# calculate site mean canopy cover and then remove unnecessary cols
trans_data <- trans_data %>%
  group_by(Sitio) %>%
  mutate(site_mean_CC = mean(tran_mean_CC)) %>%
  dplyr::select(-c('CC A', 'CC B', 'CC C', 'CC D', 'tran_mean_CC'))
```

create site_data df, only 32 rows
```{r}
site_data <- trans_data %>% 
  filter(Transecto == 1) %>%
  dplyr::select(-'Transecto')
```

now merge with environmental_site created above
```{r}
site_data <- merge(site_data, environmental_site, by = 'Sitio')
```


## add amphibian data

calculate site-level abundance, richness, diversity and merge with site_data

abundance
```{r}
abundance_by_site <- new %>%
  group_by(Sitio) %>%
  count()

site_data <- merge(site_data, abundance_by_site, by = 'Sitio')
```

richness
```{r}
richness_by_site <- new %>%
  group_by(Sitio) %>%
  summarize(species = list(sort(unique(`Final_ID`))),
            no_species = n_distinct(`Final_ID`)) %>%
  dplyr::select(-'species')

site_data <- merge(site_data, richness_by_site, by = 'Sitio')
```

diversity indices
- include Shannon, Simpson, inverse Simpson

make new_mat - intermediate step for diversity indices from vegan
```{r}
three_column <- new %>%
  group_by(Sitio) %>%
  count(`Final_ID`)

# needs to be converted to data.frame!
three_column <- data.frame(three_column)
new_mat <- matrify(three_column)

# important to check that new_mat has same order as site_data
head(new_mat)
head(site_data)
```

add each diversity index to site_data using vegan package
```{r}
# use diversity function from vegan package
site_data <- site_data %>%
    mutate(Shannon_Index = diversity(new_mat, index = "shannon")) %>%
    mutate(Simpson_Index = diversity(new_mat, index = "simpson")) %>%
    mutate(Inv_Simpson_Index = diversity(new_mat, index = "invsimpson"))
```


## scale predictors

scale values of predictor variables using scale function
- keep mean value columns as well
```{r}
site_data <- site_data %>%
  mutate(veg_scaled = as.numeric(scale(site_mean_veg)),
         hoja_scaled = as.numeric(scale(site_mean_hoja)),
         CC_scaled = as.numeric(scale(site_mean_CC)),
         forest_scaled = as.numeric(scale(forest_cover_400)),
         water_scaled = as.numeric(scale(water_dist)),
         elevation_scaled = as.numeric(scale(Elevation))
         )
```


## export site_data

```{r}
# filename <- "site_data_processed.csv"
# filepath <- file.path(data_dir, filename)
# write_csv(site_data, file = filepath)
```


#4. new_matrix

matrix for community comparisons across site types
- need to remove two sites from matrix b/c didn't sample in both seasons
- so cannot compare these communities to others b/c of 1/2 sampling effort
```{r}
new_matrix <- matrify(
  data.frame(new %>%
             group_by(Sitio) %>%
              count(`Final_ID`)))

# need to remove two sites (rows 2,3 alphabetical)
new_matrix <- new_matrix[-c(2, 3), ]

# define the desired order of rows: sun, shade, abandoned, forest
order_new_matrix <- c(2,5,14,16,19,21,22,24,26,29, # sun (n=10)
                      1,3,6,17,18,20,23,25,27,28,30, # shade (n=11)
                      7,11,12,15, # abandoned (n=4)
                      4,8,9,10,13) # forest (n=5)

# reorder rows
new_matrix <- new_matrix[order_new_matrix, ]

# output
# filename <- "new_matrix_processed.csv"
# filepath <- file.path(data_dir, filename)
# write_csv(new_matrix, file = filepath)
```

